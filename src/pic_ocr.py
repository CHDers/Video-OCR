# !/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2024/1/24 15:26
# @Author  : Yanjun Hao
# @Site    :
# @File    : OCR.py
# @Software: PyCharm
# @Comment :

# SECTION: -------------------------------æ–¹å¼1---------------------------------------
# NOTE:
#  OCRæ–‡æœ¬æ£€æµ‹
#  Linking: https://www.bilibili.com/video/BV15N4y1Q76F/?spm_id_from=333.337.search-card.all.click&vd_source=40437a7834b5b148effaa5971e14f8d6
# from paddleocr import PaddleOCR
# img_path=r'C:\Users\YanJun\Desktop\è¯†åˆ«.png'
# ocr=PaddleOCR(lang='ch')
# result = ocr.ocr(img_path)
# NOTE: DLç¯å¢ƒè¿è¡Œä¼šæŠ¥é”™ModuleNotFoundError: No module named 'paddle',
#  å¯é€šè¿‡python -m pip install paddlepaddle-gpu==2.4.2 -i https://pypi.tuna.tsinghua.edu.cn/simpleå®‰è£…GPUç‰ˆæœ¬ï¼Œæ‹…å¿ƒæ‹…å¿ƒç ´åpytorchç¯å¢ƒ
# SECTION: -------------------------------æ–¹å¼1---------------------------------------


# SECTION: -------------------------------æ–¹å¼2---------------------------------------
#  tesseractå®‰è£…åŒ…ä¸‹è½½é“¾æ¥: https://digi.bib.uni-mannheim.de/tesseract/?C=M;O=D
# https://blog.csdn.net/cxyxx12/article/details/134920510
# https://blog.csdn.net/Castlehe/article/details/118751833
# https://blog.csdn.net/wuShiJingZuo/article/details/135016582
# https://blog.csdn.net/qq_38563206/article/details/132990793


from cfg.cfg import *
from PIL import Image, ImageEnhance
import pytesseract
import easyocr
from paddleocr import PaddleOCR
import shutil
import math
import pandas as pd
import cv2
import os
from rich import print
import re
import sys
from pathlib import Path

FILE = Path(__file__).resolve()
ROOT_0 = FILE.parents[0]  # project root directory
ROOT_1 = FILE.parents[1]  # project root directory
if str(ROOT_0) not in sys.path:
    sys.path.append(str(ROOT_0))  # add ROOT to PATH
if str(ROOT_1) not in sys.path:
    sys.path.append(str(ROOT_1))  # add ROOT to PATH

pytesseract.pytesseract.tesseract_cmd = r'd:\SoftWare\Tesseract-OCR\tesseract.exe'


class IdentifyText:
    def __init__(self) -> None:
        # å®šä¹‰ç›¸ä¼¼é¢œè‰²çš„é˜ˆå€¼ï¼Œ5~200ä¹‹é—´ä¸ºæœ€ä½³å€¼ï¼Œ5~500ä¸ºæœ‰æ•ˆå€¼
        self.threshold = 100
        img_path = r'screen\screen.png'
        new_img_path = r'screen\new_screen.png'
        if self.transformedImage(img_path, new_img_path):
            print(self.characterRecognition(new_img_path))

    # è®¡ç®—ä¸¤ä¸ªé¢œè‰²ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»
    def color_distance(self, c1, c2):
        # å¦‚æœå›¾ç‰‡æ²¡æœ‰é€æ˜é€šé“åˆ™ä¸éœ€è¦ä¼ å…¥å’Œè®¡ç®—aé€šé“
        r1, g1, b1, a1 = c1
        r2, g2, b2, a2 = c2
        return math.sqrt((r1 - r2) ** 2 + (g1 - g2) ** 2 + (b1 - b2) ** 2 + (a1 - a2) ** 2)

    # è½¬åŒ–å›¾åƒä¸ºç™½åº•é»‘å­—ï¼Œä»¥æé«˜è¯†åˆ«å‡†ç¡®æ€§
    def transformedImage(self, img_path, new_img_path):
        # æ‰“å¼€åŸå›¾
        img = Image.open(img_path)
        # åˆ›å»ºä¸€ä¸ªç™½è‰²çš„èƒŒæ™¯å›¾åƒ
        new_img = Image.new('RGBA', img.size, (255, 255, 255, 255))
        # éå†æ‰€æœ‰åƒç´ ç‚¹
        for x in range(img.width):
            for y in range(img.height):
                # è·å–å½“å‰åƒç´ ç‚¹çš„é¢œè‰²
                color = img.getpixel((x, y))
                # å¦‚æœåŸå›¾å½“å‰åæ ‡é¢œè‰²ä¸ç»™å®šé¢œè‰²ç›¸ä¼¼ï¼Œåˆ™åœ¨èƒŒæ™¯å›¾ä¸­ç›¸åŒçš„åæ ‡å†™å…¥é»‘è‰²åƒç´ ç‚¹
                if self.color_distance(color, (247, 245, 244, 255)) < self.threshold:
                    new_img.putpixel((x, y), (0, 0, 0, 255))
        # ä¿å­˜æ–°å›¾åƒ
        new_img.save(new_img_path)
        return True

    # æ–‡å­—è¯†åˆ«
    def characterRecognition(self, new_img_path):
        # æ„Ÿè§‰å¥½åƒæ²¡æœ‰å¿…è¦è¿›è¡Œç°åº¦å’ŒäºŒå€¼åŒ–å¤„ç†äº†ï¼Œç™½åº•é»‘å­—çš„å‡†ç¡®æ€§æŒºé«˜çš„ï¼Œä»£ç ç•™è¿™ï¼Œä½ ä»¬è‡ªå·±çœ‹ç€æ•´
        # è¯»å–æ–°å›¾åƒ
        # img = cv2.imread(r'screen\screen2.png')
        # # å°†å›¾ç‰‡è½¬æ¢ä¸ºç°åº¦å›¾åƒ
        # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        # # å¯¹å›¾åƒè¿›è¡ŒäºŒå€¼åŒ–å¤„ç†
        # thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]
        # config = "--psm 7 --oem 3 -c tessedit_char_whitelist=0123456789"
        # text = pytesseract.image_to_string(thresh, config=config)

        # è¯»å–æ–°å›¾åƒ
        img = cv2.imread(r'screen\screen2.png')
        # è¿›è¡Œæ–‡å­—è¯†åˆ«
        # --psm 7 å•è¡Œè¯†åˆ« , --oem 3 ä½¿ç”¨ LSTM OCR å¼•æ“ , -c tessedit_char_whitelist=0123456789 åªè¯†åˆ«æ•°å­—å­—ç¬¦
        config = "--psm 7 --oem 3 -c tessedit_char_whitelist=0123456789"
        text = pytesseract.image_to_string(img, config=config)

        # é˜²æ­¢è¯†åˆ«ä¸åˆ°æŠ¥é”™
        try:
            # å»é™¤å…¶ä»–ç¬¦å·ï¼Œå¯¹æ•°å­—è¿›è¡Œé‡æ–°æ•´åˆ
            return int(''.join(filter(str.isdigit, text)))
        except Exception:
            return 'æœªèƒ½è¯†åˆ«æ–‡å­—'


class ScreenShot:
    def __init__(self, img_path) -> None:
        # å®šä¹‰ç›¸ä¼¼é¢œè‰²çš„é˜ˆå€¼ï¼Œ5~200ä¹‹é—´ä¸ºæœ€ä½³å€¼ï¼Œ5~500ä¸ºæœ‰æ•ˆå€¼
        self.threshold = 200
        self.img_path = img_path
        self.new_img_path = img_path
        self.transformedImage(self.img_path, self.new_img_path)

    # è®¡ç®—ä¸¤ä¸ªé¢œè‰²ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»
    def color_distance(self, c1, c2):
        # å¦‚æœå›¾ç‰‡æ²¡æœ‰é€æ˜é€šé“åˆ™ä¸éœ€è¦ä¼ å…¥å’Œè®¡ç®—aé€šé“
        r1, g1, b1 = c1
        r2, g2, b2 = c2
        return math.sqrt((r1 - r2) ** 2 + (g1 - g2) ** 2 + (b1 - b2) ** 2)

    # è½¬åŒ–å›¾åƒä¸ºç™½åº•é»‘å­—ï¼Œä»¥æé«˜è¯†åˆ«å‡†ç¡®æ€§
    def transformedImage(self, img_path, new_img_path):
        # æ‰“å¼€åŸå›¾
        img = Image.open(img_path)
        # åˆ›å»ºä¸€ä¸ªç™½è‰²çš„èƒŒæ™¯å›¾åƒ
        new_img = Image.new('RGB', img.size, (255, 255, 255))
        # éå†æ‰€æœ‰åƒç´ ç‚¹
        for x in range(img.width):
            for y in range(img.height):
                # è·å–å½“å‰åƒç´ ç‚¹çš„é¢œè‰²
                color = img.getpixel((x, y))
                # å¦‚æœåŸå›¾å½“å‰åæ ‡é¢œè‰²ä¸ç»™å®šé¢œè‰²ç›¸ä¼¼ï¼Œåˆ™åœ¨èƒŒæ™¯å›¾ä¸­ç›¸åŒçš„åæ ‡å†™å…¥é»‘è‰²åƒç´ ç‚¹
                if self.color_distance(color, (0, 0, 0)) < self.threshold:
                    new_img.putpixel((x, y), (0, 0, 0))
        # ä¿å­˜æ–°å›¾åƒ
        new_img.save(new_img_path)
        return True


def ocr_text_of_frame_by_paddleocr(frame_path: str) -> dict:
    """
    åŸºäºpaddleocrè¯†åˆ«æ–‡å­—
    """
    ocr = PaddleOCR(lang='ch')

    """ğŸ±â€ğŸ‘“è¯†åˆ«è¶…æ—¶å°±åœæ­¢"""
    try:
        ocr_result_list = ocr.ocr(frame_path)
        # print(ocr_result_list)

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ—¥æœŸæ—¶é—´ä¿¡æ¯
        time_match = re.search(r'\((.*?) UTC\)', ocr_result_list[0])
        time_match_ = re.search(r'\((.*?) UTO\)', ocr_result_list[0])
        if time_match:
            timestamp = time_match.group(1)
        else:
            if time_match_:
                timestamp = time_match_.group(1)
            else:
                timestamp = None

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– "Current Image: 48 / 1381"
        # pic_idx_match = re.search(r'Current Image: (\d+/\d+)', text)
        pic_idx_match = re.search(
            r'Current Image: (.+?) \| L/R Keyframes', ocr_result_list[-1])
        if pic_idx_match:
            pic_idx = pic_idx_match.group(1)
        else:
            pic_idx = None
        return {
            "timestamp": timestamp,
            "pic index": pic_idx,
            "text": ocr_result_list,
            "frame_path": frame_path,
        }

    except RuntimeError as timeout_error:
        # Tesseract processing is terminated
        print(f"ğŸ¤—ğŸ¤—ğŸ¤— [italic bold red]OCR ERROR: {frame_path}")
        return {
            "timestamp": None,
            "pic index": None,
            "text": None,
            "frame_path": frame_path,
        }


def ocr_text_of_frame_by_pytesseract(frame_path: str) -> dict:
    """
    åŸºäºpytesseractè¯†åˆ«æ–‡å­—
    """
    # NOTE: =============================Image=================================
    # ScreenShot(img_path=frame_path)
    img_by_Image = Image.open(frame_path)
    # img_by_Image = img_by_Image.convert("1")  # å›¾ç‰‡è½¬ä¸ºé»‘ç™½
    width, height = img_by_Image.size
    # img.show()

    # å›¾ç‰‡è£å‰ª
    # å°†è¦è£å‰ªçš„å›¾ç‰‡å—è·åŸå›¾å·¦è¾¹ç•Œè·å·¦è¾¹è·ç¦»ï¼Œä¸Šè¾¹ç•Œè·ä¸Šè¾¹è·ç¦»ï¼Œå³è¾¹ç•Œè·å·¦è¾¹è·ç¦»ï¼Œä¸‹è¾¹ç•Œè·ä¸Šè¾¹çš„è·ç¦»ã€‚
    pic_idx_image_box = (1980, 0, 2140, 18)
    pic_idx_crop_img = img_by_Image.crop(pic_idx_image_box)
    # time_box = (238,0,395,18)
    # time_crop_img = img.crop(time_box)
    # time_crop_img.show()

    # å¢å¼ºå›¾ç‰‡å¯¹æ¯”åº¦
    enhancer = ImageEnhance.Contrast(img_by_Image)
    img_contrast = enhancer.enhance(2.0)
    pic_idx_enhancer = ImageEnhance.Contrast(pic_idx_crop_img)
    pic_idx_img_contrast = pic_idx_enhancer.enhance(2.0)

    # æŒ‡å®šé…ç½®ï¼Œå¼€å¯å¤šåˆ—æ–‡å­—å¤„ç†
    custom_config = r'--oem 3 --psm 6'
    # custom_config = r"--psm 7 --oem 3 -c tessedit_char_whitelist=0123456789"

    """ğŸ±â€ğŸ‘“è¯†åˆ«è¶…æ—¶å°±åœæ­¢"""
    try:
        all_text = pytesseract.image_to_string(img_contrast,
                                                # lang='chi_sim',
                                                timeout=0.5,
                                                #    config=custom_config,
                                                )

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ—¥æœŸæ—¶é—´ä¿¡æ¯
        time_match = re.search(r'\((.*?) UTC\)', all_text)
        time_match_ = re.search(r'\((.*?) UTO\)', all_text)
        if time_match:
            timestamp = time_match.group(1)
        else:
            if time_match_:
                timestamp = time_match_.group(1)
            else:
                timestamp = None

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– "Current Image: 48 / 1381"
        # pic_idx_match = re.search(r'Current Image: (\d+/\d+)', text)
        pic_idx_match = re.search(
            r'Current Image: (.+?) \| L/R Keyframes', all_text)
        if pic_idx_match:
            pic_idx = pic_idx_match.group(1)
        else:
            pic_idx_text = pytesseract.image_to_string(pic_idx_img_contrast,
                                                        # lang='chi_sim',
                                                        timeout=0.5,
                                                        #    config=custom_config,
                                                        )
            second_ocr_pic_idx_match = re.search(
                r'Current Image: (.+?)', pic_idx_text)
            if second_ocr_pic_idx_match:
                pic_idx = second_ocr_pic_idx_match.group(1)
            else:
                pic_idx = None
        return {
            "timestamp": timestamp,
            "pic index": pic_idx,
            "text": all_text,
            "frame_path": frame_path,
        }
    except RuntimeError as timeout_error:
        # Tesseract processing is terminated
        print(f"ğŸ¤—ğŸ¤—ğŸ¤— [italic bold red]OCR ERROR: {frame_path}")
        return {
            "timestamp": None,
            "pic index": None,
            "text": None,
            "frame_path": frame_path,
        }


def ocr_text_of_frame_by_easyocr(frame_path: str) -> dict:
    """åŸºäºeasyocrå®ç°æ–‡å­—è¯†åˆ«

    Args:
        frame_path (str): è¦è¯†åˆ«çš„ç…§ç‰‡è·¯å¾„

    Returns:
        dict: å•å¼ å›¾ç‰‡è¯†åˆ«åçš„ç»“æœ
    """
    # https://blog.csdn.net/guokexiaohao/article/details/126317895
    reader = easyocr.Reader(
        ['en'])  # æ³¨ï¼šå½“æ‰§è¡Œç¤ºä¾‹ä»£ç æç¤ºä¸‹è½½ model æ—¶ï¼Œå¦‚æœä¸‹è½½é€Ÿåº¦æ…¢ï¼Œå¯ä»¥ä»ä»¥ä¸‹åˆ†äº«çš„äº‘ç›˜èµ„æºä¸‹è½½ï¼Œä¸‹è½½åè§£å‹åˆ° C:\Users\${å½“å‰ç”µè„‘ç”¨æˆ·}\.EasyOCR\model ç›®å½•ã€‚
    img_by_Image = Image.open(frame_path)
    try:
        all_text = reader.readtext(img_by_Image, paragraph="False")

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ—¥æœŸæ—¶é—´ä¿¡æ¯
        time_match = re.search(r'\((.*?) UTC\)', all_text[0][-1])
        time_match_ = re.search(r'\((.*?) UTO\)', all_text[0][-1])
        if time_match:
            timestamp = time_match.group(1)
        else:
            if time_match_:
                timestamp = time_match_.group(1)
            else:
                timestamp = None

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– "Current Image: 48 / 1381"
        # pic_idx_match = re.search(r'Current Image: (\d+/\d+)', text)
        pic_idx_match = re.search(r'\d.*\d', all_text[3][-1])
        if pic_idx_match:
            pic_idx = pic_idx_match.group(0)
        else:
            pic_idx = None
        return {
            "timestamp": timestamp,
            "pic index": pic_idx,
            "text": "<->".join([msg[-1] for msg in all_text]),
            "frame_path": frame_path,
        }
    except RuntimeError as timeout_error:
        # Tesseract processing is terminated
        print(f"ğŸ¤—ğŸ¤—ğŸ¤— [italic bold red]OCR ERROR: {frame_path}")
        return {
            "timestamp": None,
            "pic index": None,
            "text": None,
            "frame_path": frame_path,
        }


def split_video_to_frames(video_path: str, output_folder: Path) -> tuple:
    """å°†è§†é¢‘åˆ‡åˆ†ä¸ºä¸€å¸§ä¸€å¸§ç…§ç‰‡

    Args:
        video_path (str): è§†é¢‘è·¯å¾„
        output_folder (Path): åˆ‡åˆ†çš„ä¸€å¸§ä¸€å¸§ç…§ç‰‡çš„ä¿å­˜è·¯å¾„

    Returns:
        tuple: åˆ‡åˆ†ä¸ºå•å¸§ç…§ç‰‡æ„æˆçš„listä»¥åŠè§†é¢‘å¸§ç‡
    """
    # æ‰“å¼€è§†é¢‘æ–‡ä»¶
    cap = cv2.VideoCapture(video_path)

    # æ¸…ç©ºæ–‡ä»¶å¤¹
    shutil.rmtree(output_folder, ignore_errors=True)
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    os.makedirs(output_folder, exist_ok=True)

    # è·å–è§†é¢‘çš„å¸§ç‡
    fps = int(cap.get(cv2.CAP_PROP_FPS))

    # è¯»å–è§†é¢‘å¸§
    frame_count = 0
    frame_filename_list = []
    while True:
        ret, frame = cap.read()

        # å¦‚æœè§†é¢‘è¯»å–å®Œæ¯•ï¼Œé€€å‡ºå¾ªç¯
        if not ret:
            break

        # ä¿å­˜æ¯ä¸€å¸§ä¸ºå›¾åƒæ–‡ä»¶
        frame_filename = os.path.join(
            output_folder, f"frame_{frame_count:04d}.jpg")
        cv2.imwrite(frame_filename, frame)
        frame_filename_list.append(frame_filename)

        frame_count += 1

    # é‡Šæ”¾è§†é¢‘æ•è·å¯¹è±¡
    cap.release()
    return frame_filename_list, fps


if __name__ == "__main__":
    # è§†é¢‘æ–‡ä»¶è·¯å¾„
    video_path = "path/to/your/video.mp4"

    # è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
    output_folder = "path/to/your/output/folder"

    # è°ƒç”¨å‡½æ•°æ‹†åˆ†è§†é¢‘æˆå¸§
    split_video_to_frames(video_path, output_folder)
